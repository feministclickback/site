---
title: "Nicht OK, Google: Diskriminierung durch den Google-Algorithmus"
date: 2021-02-25T17:03:39+01:00
draft: true
categories: ["Nicht OK, Google"]
description: ""
---
Laut Internet Live Stats finden auf Google 40.000 Suchanfragen pro Sekunde statt. Wem es schwer fällt, sich diese gigante Zahl vorzustellen, kann auf der Webseite quasi {{< target-blank "live zusehen, wie die Zahl der Suchanfragen im Sekundentakt steigt" "https://www.internetlivestats.com/google-search-statistics/" >}}. In der Zeit, die du brauchst, um diesen Blogbeitrag zu lesen, verstreichen über 17 Millionen Suchanfragen.

Mit einem weltweiten {{< target-blank "Marktanteil von 83.97%" "https://www.statista.com/statistics/445974/search-engines-market-share-of-desktop-and-mobile-search-germany/" >}} besitzt Google in Deutschland das Marktmonopol an Suchmaschinen. Bei Suchanfragen auf mobilen Geräten liegt der Anteil sogar noch höher, nämlich bei 97.37%. Der Algorithmus, der bestimmt, welche Webseiten bei einer Google-Suche ganz oben angezeigt werden, ist jedoch keinesfalls “neutral” – und vertrauenswürdige Informationen liefert er auch nicht immer. Es mehren sich kritische Stimmen und auch wissenschaftliche Studien, die darauf hinweisen, dass der Algorithmus ein Diskriminierungsverstärker ist: er reproduziert und verstärkt gesellschaftliche Diskriminierungsverhältnisse.

Ohne der Komplexität des Themas auch nur ansatzweise gerecht werden zu können, soll dieser Blogbeitrag zumindest einige Eigenschaften des Algorithmus erklären, die dazu führen, dass er Diskriminierungen hervorbringt. Dazu schauen wir uns 5 Dimensionen genauer an.

## 1. Wie es in den Algorithmus hinein schallt, so hallt es wieder heraus

In “Algorithms of Oppression” (2018), der vermutlich umfassendsten wissenschaftlichen Studie zu dem Thema, problematisiert die US-amerikanische Medienwissenschaftlerin Safiya Umoja Noble, dass Google-Suchen nach “black girls” zum Zeitpunkt ihrer Datenerhebung mehrheitlich pornografische Webseiten anzeigten. Für das Pendant “white girls” war dies nicht der Fall.

Noble zeigt in ihrem Buch auf, dass es sich dabei nicht um einen Ausrutscher handelt, sondern dass die Repräsentation von marginalisierten Gruppen in den Google-Suchergebnissen durchweg von rassistischen und sexistischen Stereotypen geprägt ist. Sie führt das zurück auf das Mehrheitsprinzip, das dem Algorithmus zugrunde liegt: Diejenigen Webseiten, die die meisten Klicks bekommen, rutschen in den Suchergebnissen weiter nach oben.

Vereinfacht gesagt: In einer rassistischen Gesellschaft kommt auch auf Google Rassismus nach oben. So schreibt auch die Germanistin und Expertin für feministische Netzpolitik Francesca Schmidt, dass {{< target-blank "die Datenbasis, mit der Algorithmen arbeiten, auch die Ergebnisse der algorithmischen Entscheidungen beeinflusst" "https://www.gwi-boell.de/de/2021/02/04/sexismus-und-rassismus-im-code-diskriminierung-oder-gerechtigkeit-durch-algorithmen" >}}. Wenn Rassismus und Sexismus (genauso wie andere Diskriminierungsverhältnisse) in den Daten vorhanden sind, mit denen die Algorithmen gefüttert werden, ist das Endergebnis genauso diskriminierend. Dabei wird die Diskriminierung nicht nur abgebildet, sondern auch verstärkt, weil die Entscheidungen von Algorithmen eine immer stärkere Rolle in unserem Leben spielen und beeinflussen, wie wir unsere Umwelt sehen.

Nach der Veröffentlichung von Safiya Umoja Nobles Buch entfernte Google übrigens stillschweigend die kritisierten Suchergebnisse. {{< target-blank "Ein jüngerer Bericht von Leon Yin und Aaron Sankin" "https://themarkup.org/google-the-giant/2020/07/23/google-advertising-keywords-black-girls" >}} weist jedoch darauf hin, dass das exakt gleiche Problem im Google Keyword Planner (dem Tool, das Marketing-Expert:innen nutzen, um Suchbegriffe für Google-Anzeigen zu recherchieren) bis 2020 fortbestand: Wer im Tool nach Vorschlägen für verwandte Suchbegriffe zu “black girls” suchte, bekam 435 Suchbegriffe angezeigt, von denen 203 als pornografisch markiert wurden. Für “white girls” gab es interessanterweise 0 Vorschläge.


## 2. Google stuft Webseiten als relevant ein, ohne sich darum zu kümmern, welche Inhalte sie eigentlich verbreiten

Ein Faktor, der bei Google mitbestimmt, ob eine Webseite für einen Suchbegriffe weiter oben angezeigt wird, ist, wie ausführlich deren Inhalte sind. Die ausführlichsten Texte ranken tendenziell höher als kurze Texte. Problematisch ist das bei diesem Suchbegriff:

{{< figure src="/images/uploads/Nextcloud_Kollaboratives Arbeiten_780.jpg" title="" alt="">}}

Wie der Screenshot zeigt, listet Google bei einer Suche nach “Flüchtlinge Kriminalität” eine extrem rechte Webseite als 1. Treffer. Die Seite hetzt gegen Geflüchtete, indem sie Vorfälle von Kriminalität durch Geflüchtete sammelt und verbreitet. Damit sollen Geflüchtete als “von Natur aus” krimineller als andere Bevölkerungsgruppen dargestellt werden.

In der Logik des Google-Algorithmus ist sie damit am relevantesten für den Suchbegriff, weil sie von allen anderen Webseiten die meisten Inhalte zu dem Thema enthält. Welche Inhalte das sind, und welche gesellschaftlichen Auswirkungen ein solches Suchergebnis hat, spielt keine Rolle.

## 3. Google verstärkt das Weltbild, das Menschen schon haben

Das Beispiel von “Flüchtlinge Kriminalität” verdeutlicht gleich eine weitere Dimension: Die Google-Suchergebnisse verstärken in der Regel das Weltbild, das Nutzer:innen schon hatten, als sie die Suchanfrage starteten. Wer nach “Flüchtlinge Kriminalität” sucht, ist zumindest schon mit der rassistischen Hypothese, die dahinter steht, in Berührung gekommen und davon beeinflusst, auch wenn die Person sich in ihrer Haltung eventuell noch nicht sicher ist. Eine Google-Suche bestätigt rassistische Vorannahmen und bestärkt sie damit. Und wer schon ein gefestigtes rassistisches Weltbild hat, der kann sich in seinen Ansichten durch Google-Suchen bekräftigen lassen und Anschluss zu rechten Netzwerken finden.

Dieses Verstärker-Prinzip gilt nicht nur für rechtsradikale Weltsichten, richtet in dem Fall aber besonders viel Schaden an. Dylann Roof, der Attentäter, der 2015 in einer Kirche in Charleston, USA, neun Schwarze Menschen ermordete, gab an, dass er Google-Suchen nach “black on white crime” genutzt hatte, um sich in seinem Hass auf Schwarze Menschen zu radikalisieren.

## 4. Google will für jede Frage genau eine richtige Antwort liefern – und das geht regelmäßig schief.

Die Google-Suchergebnisse sahen lange relativ einfach aus: 10 blaue Links, oben einige bezahlte Anzeigen. Mittlerweile finden sich dort jedoch noch eine Vielzahl anderer Elemente, unter ihnen Definitionen, Frage-und-Antwort-Boxen und Antworten auf Fragen direkt in den Suchergebnissen. Wenn Google Auszüge aus anderen Webseiten direkt in den Suchergebnissen anzeigt,  um Nutzer:innen die Antwort auf ihre Suchanfrage direkt zu liefern, ohne dass sie Google verlassen müssen, nennt sich das “Rich Result".

Die 10 blauen Links sind damit immer weiter nach unten gerückt. {{< target-blank "Einer Studie von Leon Yin und Adrienne Jeffries" "https://themarkup.org/google-the-giant/2020/07/28/how-we-analyzed-google-search-results-web-assay-parsing-tool" >}} aus dem Jahr 2020 zufolge nehmen Inhalte, die direkt von Google kommen, 62.6% der ersten Bildschirmansicht ein (d.h. ohne Scrollen), und 42% der ersten Seite (mit Scrollen). Inhalte, die nicht von Google stammen, befanden sich dabei im mittleren bis unteren Abschnitt der Seite.

Google verschafft sich selbst damit mehr Sichtbarkeit in den Suchergebnissen. Die Entscheidung, welche Textauszüge aus welcher Webseite angezeigt werden, trifft eine Maschine, die, wie die Autor:innen der oben zitierten Studie problematisieren, auch daneben liegen kann – in einigen Fällen enthielten Rich Results zutiefst sexistische und rassistische Inhalte.

Dazu zwei Beispiele von Google Deutschland:














Bei diesem Beispiel wurde gemäß dem Verstärker-Effekt für einen antifeministisch geprägten Suchbegriff (“Gender-Ideologie” – ein {{< target-blank "antifeministischer Kampfbegriff" "https://www.gwi-boell.de/de/2018/08/03/frauenfeindlich-sexistisch-antifeministisch-begriffe-und-phaenomene-bis-zum-aktuellen" >}}) eine antifeministische Webseite für ein Rich Snippet ausgewählt. Das Pew-Research-Center kam 2012 in einer Studie zu dem Schluss, dass 66% der Befragten der Meinung waren, Suchmaschinen seien eine “faire und unparteiische” Informationsquelle. Vor diesem Hintergrund ist zu vermuten, dass die Auswahl der Webseite für eine Definition des Begriffs “Gender-Ideologie” von Nutzer:innen als vertrauenswürdig eingestuft wird. In jedem Fall verleiht Google der antifeministischen Webseite hiermit eine herausgehobene Stellung und verleiht ihr damit mehr Autorität.

Den gleichen Effekt hat dieses Rich Snippet, bei dem eine Webseite von christlich-fundamentalistischen Abtreibungsgegner:innen hervorgehoben wird:
















Die Webseite täuscht gezielt vor, eine vertrauenswürdige Quelle zum Thema Schwangerschaftsabbruch zu sein, um ungewollt Schwangere zu erreichen. Dieser Strategie leistet Google durch das Rich Snippet Vorschub.

5. SEO kostet Zeit und Geld

Der letzte Grund, warum der Google-Algorithmus gesellschaftliche Diskriminierungsverhältnisse verstärkt, ist der Aufwand, den es kostet, durch SEO die eigenen Inhalte prominenter zu platzieren. SEO kostet Zeit und Geld: Firmen, Online-Magazine und Online-Zeitungen investieren viel Geld, damit SEO-Expert:innen ihre Inhalte für Suchmaschinen optimiert. Kleine Webseiten und vor allem politische Initiativen, hinter denen keine großen finanziellen Ressourcen stecken, haben einen entscheidenden Nachteil.

In einer Gesellschaft, in der die Ressourcen Zeit und Geld ungleich verteilt sind, haben marginalisierte Gruppen eine schlechtere Chance, sich im digitalen Raum Sichtbarkeit zu verschaffen. Die gleichen Diskriminierungsverhältnisse, die dazu führen, dass diese Gruppen über weniger Zeit und Geld verfügen, werden in der Folge vom Google-Algorithmus verstärkt.

Was tun?

Eines ist klar: So, wie der Algorithmus aktuell funktioniert, hat er negative Auswirkungen auf die Gesellschaft. Und dies ist ein systematisches Problem, das in der Funktionsweise des Algorithmus selbst angelegt ist.

Das Problem zu beheben ist nicht einfach. {{< target-blank "Safiya Umoja Noble geht davon aus, dass selbst die Google-Ingenieur:innen nicht in der Lage sind, das Problem zu beheben, weil selbst sie den seit 20 Jahren kontinuierlich weiter entwickelten Algorithmus nicht mehr durchschauen." "https://themarkup.org/google-the-giant/2020/07/23/google-advertising-keywords-black-girls" >}}
Ein erster wichtiger Schritt wäre, die Funktionsweise des Algorithmus für die Öffentlichkeit transparent zu machen. Bisher lässt Google sich nicht in die Karten schauen, wie genau die Suchergebnisse zustande kommen. Und selbst Googles eigene Forscher:innen dürfen nicht unabhängig zu den gesellschaftlichen Auswirkungen von Google-Produkten forschen, {{< target-blank "wie die Kündigung der Wissenschaftlerin Timnit Gebru gezeigt hat" "https://googlewalkout.medium.com/standing-with-dr-timnit-gebru-isupporttimnit-believeblackwomen-6dadc300d382" >}}. Dabei sind Transparenz und unabhängige Forschung wichtig, um Lösungen für die komplexen Probleme von algorithmischen Entscheidungen zu finden.

Schließlich braucht es eine Demokratisierung von Internetkonzernen wie Google. {{< target-blank "Netzpolitik.org hat dazu einige bereits konkrete Vorschläge gemacht." "https://netzpolitik.org/2018/den-datenfischern-die-netze-kappen-ideen-gegen-die-marktmacht-der-plattformen/" >}} Wer einen so großen Einfluss auf die öffentliche Meinungsbildung und den Zugang zu Informationen, darf nicht weiter im stillen Kämmerchen sitzen und hinter verschlossenen Türen entscheiden, wer und was Sichtbarkeit bekommt, und was nicht.
