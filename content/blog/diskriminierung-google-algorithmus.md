---
title: "Nicht OK, Google: Diskriminierung durch den Google-Algorithmus"
date: 2021-02-25T17:03:39+01:00
draft: false
categories: ["Nicht OK, Google"]
description: "Verstärkt der Google-Algorithmus Diskriminierung? Wir sagen, ja - und in diesem Beitrag erklären wir, warum."
---
Laut Internet Live Stats finden auf Google 40.000 Suchanfragen pro Sekunde statt. Wem es schwer fällt, sich diese gigantische Zahl vorzustellen, kann auf der Webseite quasi live zusehen, {{< target-blank "wie die Zahl der Suchanfragen im Sekundentakt steigt" "https://www.internetlivestats.com/google-search-statistics/" >}}. In der Zeit, die du brauchst, um diesen Blogbeitrag zu lesen, verstreichen über 17 Millionen Suchanfragen.

Mit einem weltweiten {{< target-blank "Marktanteil von 83.97%" "https://www.statista.com/statistics/445974/search-engines-market-share-of-desktop-and-mobile-search-germany/" >}} besitzt Google in Deutschland das Marktmonopol an Suchmaschinen. Bei Suchanfragen auf mobilen Geräten liegt der Anteil sogar noch höher, nämlich bei 97.37%. Der Algorithmus, der bestimmt, welche Webseiten bei einer Google-Suche ganz oben angezeigt werden, ist jedoch keinesfalls “neutral” – und vertrauenswürdige Informationen liefert er auch nicht immer. Es mehren sich kritische Stimmen und auch wissenschaftliche Studien weisen darauf hin, dass der Algorithmus gesellschaftliche Diskriminierungsverhältnisse verstärkt.

Ohne der Komplexität des Themas auch nur ansatzweise gerecht werden zu können, soll dieser Blogbeitrag einige Eigenschaften des Algorithmus erklären, die zu diesem Effekt führen. Dazu schauen wir uns vier Dimensionen genauer an.

## 1. Wie es in den Algorithmus hinein schallt, so hallt es wieder heraus

In “Algorithms of Oppression” (2018), der vermutlich umfassendsten wissenschaftlichen Studie zu dem Thema, problematisiert die US-amerikanische Medienwissenschaftlerin Safiya Umoja Noble, dass Google-Suchen nach “black girls” zum Zeitpunkt ihrer Datenerhebung mehrheitlich pornografische Webseiten anzeigten. Für das Pendant “white girls” war dies nicht der Fall.

Noble zeigt in ihrem Buch auf, dass es sich dabei nicht um einen Zufall handelt, sondern dass die Repräsentation von marginalisierten Gruppen in den Google-Suchergebnissen durchweg von rassistischen und sexistischen Stereotypen geprägt ist. Sie führt dies zurück auf das Mehrheitsprinzip, welches dem Algorithmus zugrunde liegt: Diejenigen Webseiten, die die meisten Klicks bekommen, rutschen in den Suchergebnissen weiter nach oben.

Vereinfacht gesagt: In einer rassistischen Gesellschaft kommt auch auf Google rassistische Beiträge nach oben. So schreibt die Germanistin und Expertin für feministische Netzpolitik Francesca Schmidt, dass {{< target-blank "die Datenbasis, mit der Algorithmen arbeiten, auch die Ergebnisse der algorithmischen Entscheidungen beeinflusst" "https://www.gwi-boell.de/de/2021/02/04/sexismus-und-rassismus-im-code-diskriminierung-oder-gerechtigkeit-durch-algorithmen" >}}. Wenn Rassismus und Sexismus (genauso wie andere Diskriminierungsverhältnisse) in den Daten vorhanden sind, mit denen die Algorithmen gefüttert werden, ist das Endergebnis ebenso diskriminierend. Dabei wird die Diskriminierung nicht nur abgebildet, sondern auch verstärkt, weil Algorithmen in einer zunehmend digitalisierten Welt immer häufiger zum Einsatz kommen, demnach eine große Rolle in unserem Leben spielen und beeinflussen, wie wir unsere Umwelt sehen.

Nach der Veröffentlichung von Safiya Umoja Nobles Buch entfernte Google übrigens stillschweigend die kritisierten Suchergebnisse. {{< target-blank "Ein jüngerer Bericht von Leon Yin und Aaron Sankin" "https://themarkup.org/google-the-giant/2020/07/23/google-advertising-keywords-black-girls" >}} weist jedoch darauf hin, dass das exakt gleiche Problem im Google Keyword Planner (dem Tool, das Marketing-Expert:innen nutzen, um Suchbegriffe für Google-Anzeigen zu recherchieren) bis 2020 fortbestand: Wer im Tool nach Vorschlägen für verwandte Suchbegriffe zu “black girls” suchte, bekam 435 Suchbegriffe angezeigt, von denen 203 als pornografisch markiert wurden. Für “white girls” gab es interessanterweise null Vorschläge.

## 2. Google verstärkt das eigene Weltbild

Die Google-Suchergebnisse verstärken in der Regel das Weltbild, welches Nutzer:innen schon hatten, als sie die Suchanfrage starteten.

Dazu ein Beispiel: Nach der Kölner Silvesternacht 2015 spiegelte sich die (rassistisch geprägte) Debatte in der deutschen Presse auch im Suchverhalten der Google-Nutzer:innen wider. Im darauffolgenden Januar 2016 stiegen die Google-Suchen nach “Übergriffe von Flüchtlingen”, “sexuelle Übergriffe Flüchtlinge” und sogar “Flüchtlinge raus” stark an (Quelle: Google Trends für das Thema “Refugee” in Deutschland vom 01.01. - 31.01.2016, Abruf am 25.02.2021). Nutzer:innen, die Suchbegriffe aus dem Themenbereich Flucht suchten, googelten plötzlich auch nach Suchbegriffen aus dem Themenbereich Kriminalität in Deutschland (Zunahme von 1,100 %) und Vergewaltigung (Zunahme von 400%, Quelle: Google Trends, Abruf am 25.02.2021, siehe oben).

Diese Daten fließen in den Suchalgorithmus ein und beeinflussen diesen – zum Teil noch Jahre später. 2018, also drei Jahre nach den Ereignissen in Köln, schlug Google-Autocomplete den Begriff “Flüchtlinge Kriminalität” vor, nachdem nur das Wort “Flüchtlinge” getippt wurde:

{{< figure src="/images/fluechtlinge-autocomplete.png" title="Screenshot von August 2018" alt="Google-Screenshot: Wort Flüchtlinge ist eingetippt, Autocomplete schlägt als Vorschlag 'Flüchtlinge Kriminalität' vor">}}

Wer bis mindestens August 2019 diesen Begriff googelte, landete auf dem ersten Platz bei einer rechtsextremen Webseite (Quelle: kwfinder.com, Abruf am 25.02.2021).

{{< figure src="/images/serps-fluechtlinge_aug 18.png" title="Screenshot vom April 2019" alt="Google-Screenshot: Suchergebnisse für Suche nach 'Flüchtlinge Kriminalität', erstes Ergebnis ist politikversagen.net">}}

Damit bestätigt diese Google-Suche die rassistische Vorannahme, die im Suchbegriff schon angelegt wird. Wer nach “Flüchtlinge Kriminalität” sucht, ist zumindest schon mit der dahinterstehenden, rassistischen Hypothese in Berührung gekommen und davon beeinflusst, auch wenn die Person sich ihrer Haltung eventuell noch nicht sicher ist. Die Google-Suche bestätigt somit rassistische Vorannahmen und bestärkt sie. Und wer schon ein gefestigtes rassistisches Weltbild hat, der kann sich in seinen Ansichten durch Google-Suchen bekräftigen lassen und Anschluss zu rechten Netzwerken finden.

Dieses Verstärker-Prinzip gilt nicht nur für rechtsradikale Weltsichten, richtet in dem Fall aber besonders viel Schaden an. Der Attentäter Dylann Roof, der 2015 in einer Kirche in Charleston, USA, neun Schwarze Menschen ermordete, gab an, dass er Google-Suchen nach “black on white crime” genutzt hatte, um sich in seinem Hass auf Schwarze Menschen zu radikalisieren.

Mittlerweile haben vertrauenswürdigere journalistische Angebote die extrem rechte Webseite aus den Suchergebnissen verdrängt. Die demokratische Zivilgesellschaft greift regelmäßig derartige Themen auf, um sie mit Fakten zu widerlegen. Sie hinkt damit jedoch immer der Zeit hinterher. Das Suchvolumen für die genannten Suchbegriffe nahm seit 2016 kontinuierlich ab, d.h. die aktuellen Suchergebnisse bekommen weniger Menschen zu Gesicht. In dem Zeitraum direkt nach der Kölner Silvesternacht, als das Suchvolumen am höchsten war, dominierten rassistische Webseiten die Suchergebnisse.

Da der Google-Algorithmus sich prinzipiell nicht dafür interessiert, welchen politischen Hintergrund eine Webseite hat und ob die darin enthaltenen Informationen vertrauenswürdig sind oder nicht, wird sich das hier beschriebene Prinzip wiederholen, wenn es die nächste rassistische Debatte oder den nächsten rechten Kampfbegriff gibt.

## 3. Google will für jede Frage *genau eine* richtige Antwort liefern – und das geht regelmäßig schief.

Die Google-Suchergebnisse sahen lange relativ einfach aus: zehn blaue Links, oben einige bezahlte Anzeigen. Mittlerweile finden sich dort jedoch noch eine Vielzahl anderer Elemente, unter ihnen Definitionen, Frage-und-Antwort-Boxen und Antworten auf Fragen direkt in den Suchergebnissen. Wenn Google Auszüge aus anderen Webseiten direkt in den Suchergebnissen anzeigt, um Nutzer:innen die Antwort auf ihre Suchanfrage direkt zu liefern, ohne dass sie Google verlassen müssen, nennt sich dies “Rich Result”.

Die zehn blauen Links sind damit immer weiter nach unten gerückt. Einer {{< target-blank "Studie von Leon Yin und Adrienne Jeffries" "https://themarkup.org/google-the-giant/2020/07/28/how-we-analyzed-google-search-results-web-assay-parsing-tool" >}} zufolge nehmen Inhalte, die direkt von Google kommen, 62,6% der ersten Bildschirmansicht ein (d.h. ohne Scrollen) und 42% der ersten Seite (mit Scrollen). Inhalte, die nicht von Google stammen, befanden sich dabei im mittleren bis unteren Abschnitt der Seite.

Google verschafft sich selbst damit mehr Sichtbarkeit in den Suchergebnissen. Die Entscheidung, welche Textauszüge aus welcher Webseite angezeigt werden, trifft eine Maschine, die, wie die Autor:innen der oben zitierten Studie problematisieren, auch falsch liegen kann – in einigen Fällen enthielten Rich Results zutiefst sexistische und rassistische Inhalte.

Dazu zwei Beispiele von Google Deutschland:

{{< figure src="/images/feat snippet_ april 19.png" title="Screenshot von April 2019" alt="Google-Screenshot: Suche nach 'Gender-Ideologie' zeigt als erstes Definition einer antifeministischen Webseite an.">}}

Bei diesem Beispiel wurde gemäß dem Verstärker-Effekt für einen antifeministisch geprägten Suchbegriff (“Gender-Ideologie” – ein {{< target-blank "antifeministischer Kampfbegriff" "https://www.gwi-boell.de/de/2018/08/03/frauenfeindlich-sexistisch-antifeministisch-begriffe-und-phaenomene-bis-zum-aktuellen" >}}) eine antifeministische Webseite für ein Rich Snippet ausgewählt. Das Pew-Research-Center kam 2012 in einer {{< target-blank "Studie" "https://www.pewresearch.org/internet/2012/03/09/search-engine-use-2012/" >}} zu dem Schluss, dass 66% der Befragten der Meinung waren, Suchmaschinen seien eine “faire und unparteiische” Informationsquelle. Vor diesem Hintergrund ist zu vermuten, dass die Auswahl der Webseite für eine Definition des Begriffs “Gender-Ideologie” von Nutzer:innen als vertrauenswürdig eingestuft wird. In jedem Fall verleiht Google der antifeministischen Webseite hiermit eine herausgehobene Stellung und damit mehr Autorität.

Den gleichen Effekt hat dieses Rich Snippet, bei dem eine Webseite von christlich-fundamentalistischen Abtreibungsgegner:innen hervorgehoben wird:

{{< figure src="/images/profemina featured snippet 2.png" title="Screenshot von August 2018" alt="Screenshot der Google-Suche, Modul 'Andere Nutzer fragen auch', bei der Frage 'Wann abtreiben?' wird die Webseite von Pro Femina zitiert und verlinkt.">}}

Die Webseite täuscht gezielt vor, eine vertrauenswürdige Quelle zum Thema Schwangerschaftsabbruch zu sein, um ungewollt Schwangere zu erreichen. Dieser Strategie leistet Google durch das Rich Snippet Vorschub.

## 4. SEO kostet Zeit und Geld

Der letzte Grund, warum der Google-Algorithmus gesellschaftliche Diskriminierungsverhältnisse verstärkt, ist der Aufwand, den es kostet, durch SEO die eigenen Inhalte prominenter zu platzieren. SEO kostet Zeit und Geld: Firmen, Online-Magazine und Online-Zeitungen investieren zum Teil hohe Summen, damit SEO-Expert:innen ihre Inhalte für Suchmaschinen optimieren. Kleine Webseiten und vor allem politische Initiativen, hinter denen keine großen finanziellen Ressourcen stecken, haben hier einen entscheidenden Nachteil.

In einer Gesellschaft, in der Zeit und Geld ungleich verteilt sind, haben marginalisierte Gruppen eine schlechtere Chance, sich im digitalen Raum Sichtbarkeit zu verschaffen. Die gleichen Diskriminierungsverhältnisse, die dazu führen, dass diese Gruppen über weniger Zeit und Geld verfügen, werden in der Folge vom Google-Algorithmus verstärkt.

## Was tun?

Eines ist klar: So, wie der Algorithmus aktuell funktioniert, hat er negative Auswirkungen auf die Gesellschaft. Und dies ist ein strukturelles Problem, welches in der Funktionsweise des Algorithmus selbst angelegt ist.

Das Problem zu beheben ist nicht einfach. {{< target-blank "Safiya Umoja Noble geht davon aus, dass selbst die Google-Ingenieur:innen nicht in der Lage sind, das Problem zu beheben, weil selbst sie den seit 20 Jahren kontinuierlich weiter entwickelten Algorithmus nicht mehr durchschauen." "https://themarkup.org/google-the-giant/2020/07/23/google-advertising-keywords-black-girls" >}}
Ein erster wichtiger Schritt wäre, die Funktionsweise des Algorithmus für die Öffentlichkeit transparent zu machen. Bisher lässt Google sich nicht in die Karten schauen, wie genau die Suchergebnisse zustande kommen. Und selbst Googles eigene Forscher:innen dürfen nicht unabhängig zu den gesellschaftlichen Auswirkungen von Google-Produkten forschen, {{< target-blank "wie die Kündigung der Wissenschaftlerin Timnit Gebru gezeigt hat" "https://googlewalkout.medium.com/standing-with-dr-timnit-gebru-isupporttimnit-believeblackwomen-6dadc300d382" >}} Dabei sind Transparenz und unabhängige Forschung wichtig, um Lösungen für die komplexen Probleme von algorithmischen Entscheidungen zu finden.

Letztendlich braucht es eine Demokratisierung von Internetkonzernen wie Google. {{< target-blank "Netzpolitik.org hat dazu bereits einige konkrete Vorschläge gemacht." "https://netzpolitik.org/2018/den-datenfischern-die-netze-kappen-ideen-gegen-die-marktmacht-der-plattformen/" >}} Wer einen so großen Einfluss auf die öffentliche Meinungsbildung und den Zugang zu Informationen hat, darf nicht weiter im stillen Kämmerchen sitzen und hinter verschlossenen Türen entscheiden, wer und was digitale Sichtbarkeit bekommt.
